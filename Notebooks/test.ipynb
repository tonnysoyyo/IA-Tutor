{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea81add7",
   "metadata": {},
   "source": [
    "# **Run all of these codes using a GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23b955",
   "metadata": {},
   "source": [
    "# Test for Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572e44f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "  from transformers import pipeline\n",
    "  from langchain_huggingface import HuggingFacePipeline\n",
    "  from langchain.prompts import PromptTemplate\n",
    "  from transformers.utils.logging import set_verbosity_error\n",
    "\n",
    "  set_verbosity_error()\n",
    "\n",
    "  # Use Phi-2 for math solving\n",
    "  math_pipeline = pipeline(\n",
    "      \"text-generation\",\n",
    "      model=\"microsoft/phi-2\", # hjskhan/gemma-2b-fine-tuned-math\n",
    "      device=0,\n",
    "      max_new_tokens=256,  # ðŸ’¡ increase for full explanation\n",
    "      temperature=0.7,\n",
    "      do_sample=True\n",
    "  )\n",
    "\n",
    "  math_solver = HuggingFacePipeline(pipeline=math_pipeline)\n",
    "\n",
    "  # QA model (same as before)\n",
    "  qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\", device=-1)\n",
    "\n",
    "  # Prompt to force step-by-step reasoning\n",
    "  math_template = PromptTemplate.from_template(\n",
    "      \"You are a math expert. Solve the following problem step-by-step and explain clearly:\\n\\n{problem}\\n\\nSolution:\"\n",
    "  )\n",
    "\n",
    "  # Chain definition\n",
    "  math_chain = math_template | math_solver\n",
    "\n",
    "  # Ask for math problem\n",
    "  problem = input(\"\\nEnter a math problem (e.g. 'What is the derivative of x^2 + 3x?'):\\n\")\n",
    "\n",
    "  # Generate the answer\n",
    "  solution = math_chain.invoke({\"problem\": problem})\n",
    "\n",
    "  print(\"\\nðŸ”¹ **Solution Explanation:**\")\n",
    "  print(solution)\n",
    "\n",
    "  # QA loop\n",
    "  while True:\n",
    "      question = input(\"\\nAsk a question about the solution (or type 'exit' to stop):\\n\")\n",
    "      if question.lower() == \"exit\":\n",
    "          break\n",
    "\n",
    "      qa_result = qa_pipeline(question=question, context=solution)++++\n",
    "      print(\"\\nðŸ”¹ **Answer:**\")\n",
    "      print(qa_result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf9376",
   "metadata": {},
   "source": [
    "# Test for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9773cf7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers.utils.logging import set_verbosity_error\n",
    "\n",
    "set_verbosity_error()\n",
    "\n",
    "summarization_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "summarizer = HuggingFacePipeline(pipeline=summarization_pipeline)\n",
    "\n",
    "refinement_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large\", device=0)\n",
    "refiner = HuggingFacePipeline(pipeline=refinement_pipeline)\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", device=0)\n",
    "\n",
    "summary_template = PromptTemplate.from_template(\"Summarize the following text in a {length} way:\\n\\n{text}\")\n",
    "\n",
    "summarization_chain = summary_template | summarizer | refiner\n",
    "\n",
    "text_to_summarize = input(\"\\nEnter text to summarize:\\n\")\n",
    "length = input(\"\\nEnter the length (short/medium/long): \")\n",
    "\n",
    "summary = summarization_chain.invoke({\"text\": text_to_summarize, \"length\": length})\n",
    "\n",
    "print(\"\\nðŸ”¹ **Generated Summary:**\")\n",
    "print(summary)\n",
    "\n",
    "while True:\n",
    "    question = input(\"\\nAsk a question about the summary (or type 'exit' to stop):\\n\")\n",
    "    if question.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    qa_result = qa_pipeline(question=question, context=summary)\n",
    "\n",
    "    print(\"\\nðŸ”¹ **Answer:**\")\n",
    "    print(qa_result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
